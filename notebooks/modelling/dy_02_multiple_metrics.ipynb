{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import mlflow\n",
    "import mlflow.xgboost\n",
    "from mlflow.models import infer_signature\n",
    "from mlflow.tracking import MlflowClient\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import optuna\n",
    "from optuna.integration.mlflow import MLflowCallback\n",
    "import joblib\n",
    "\n",
    "from typing import Optional, Dict, Tuple, Literal\n",
    "from enefit_challenge.models.forecaster import Forecaster\n",
    "from enefit_challenge.utils.dataset import load_enefit_training_data\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "TRACKING_URI = \"http://127.0.0.1:5000/\" # local tracking URI -> launch mlflow before training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Metrics\n",
    "In the Enefit Challenge, our models have to minimize MAE (Mean Absolute Error) to win the competition.  \n",
    "However, it might make sense to track multiple time-series metrics during experiment runs to keep in check unwanted behaviours of our models that MAE simply does not catch. \n",
    "Some of the metrics that we want to track include:\n",
    "* MAPE (Mean Absolute Percentage Error)\n",
    "* RMSE (Root Mean Squared Error)\n",
    "* sMAE (Symmetric MAE)\n",
    "* sMAPE (Symmetric MAPE)\n",
    "\n",
    "-> how to keep track of multiple metrics? With optuna or with mlflow? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = load_enefit_training_data()\n",
    "\n",
    "not_feature_columns = ['datetime', 'row_id','prediction_unit_id','date','time', 'data_block_id']\n",
    "cat_columns = ['county', 'product_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XGBoostForecaster(Forecaster):\n",
    "    \"\"\"\n",
    "        Implementation of a Forecaster using `XGBRegressor` as base model, \n",
    "        `optuna` for hyperparameters optimization and `mlflow` as backend to track experiments\n",
    "        and register best-in-class model for time series prediction.\n",
    "    \"\"\"\n",
    "    def __init__(self)-> None:\n",
    "        self.tracking_uri = mlflow.set_tracking_uri(TRACKING_URI)\n",
    "        pass\n",
    "\n",
    "    def fit_model(\n",
    "        self,  \n",
    "        X:pd.DataFrame,\n",
    "        y:pd.Series,\n",
    "        params:Optional[Dict]=None,\n",
    "    ) -> XGBRegressor:\n",
    "        \"\"\"\n",
    "        Trains a `XGBRegressor`\n",
    "\n",
    "        -------     \n",
    "        params:\n",
    "        -------\n",
    "        `X`:`pd.DataFrame`\n",
    "            Features to use for fitting\n",
    "        `y`:`pd.Series`\n",
    "            Target variable\n",
    "        `params`: `Optional[Dict]`\n",
    "            optional dictionary of parameters to use\n",
    "        -------     \n",
    "        returns:\n",
    "        -------\n",
    "        fitted `XGBRegressor`\n",
    "        \"\"\"\n",
    "        model = XGBRegressor(\n",
    "            n_estimators=100, \n",
    "            objective='reg:squarederror',\n",
    "            eval_metric='mae'\n",
    "        )\n",
    "        if params:\n",
    "            model.set_params(**params)\n",
    "\n",
    "        model.fit(X, y)\n",
    "    \n",
    "        return model\n",
    "    \n",
    "    def fit_and_test_fold(\n",
    "        self, \n",
    "        params:Dict,\n",
    "        X: pd.DataFrame, \n",
    "        y: pd.Series, \n",
    "        year_month_train, \n",
    "        year_month_test,\n",
    "        experiment_name: str=\"xgboost\",\n",
    "        artifact_path: str=\"xgboost_model\",\n",
    "        metrics: list=[\"mae\"]\n",
    "    ) -> float:\n",
    "        \"\"\"\n",
    "        Used for cross validation on different time splits; \n",
    "        also in charge of logging every experiment run / study trial into the backend.\n",
    "        \"\"\"\n",
    "        \n",
    "        first_dates_month = pd.to_datetime(X[['year', 'month']].assign(day=1))\n",
    "        train_index = first_dates_month.isin(year_month_train)\n",
    "        test_index = first_dates_month.isin(year_month_test)\n",
    "\n",
    "        X_train = X[train_index]\n",
    "        X_test = X[test_index]\n",
    "        y_train = y[train_index]\n",
    "        y_test = y[test_index]\n",
    "\n",
    "        # fit model on training data\n",
    "        model = self.fit_model(\n",
    "            X_train, \n",
    "            y_train, \n",
    "            params\n",
    "        )\n",
    "        \n",
    "        # generate predictions\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        self.signature = infer_signature(X_train, y_test_pred)\n",
    "        mae = mean_absolute_error(y_test, y_test_pred)\n",
    "        mape = mean_absolute_percentage_error(y_test, y_test_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "        mlflow.xgboost.log_model(\n",
    "            model, \n",
    "            artifact_path=artifact_path,\n",
    "            signature=self.signature\n",
    "        )\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        return mae, mape, rmse\n",
    "\n",
    "    def train_model(\n",
    "        self, \n",
    "        train_df: pd.DataFrame, \n",
    "        target_col: str,\n",
    "        model_name: str,\n",
    "        exclude_cols: list=[],\n",
    "        categorical_features: list=[],\n",
    "        experiment_name: str=\"xgboost\",\n",
    "        artifact_path: str=\"xgboost_model\",\n",
    "        params: Optional[Dict]=None\n",
    "    ) -> None:\n",
    "        \"\"\" \n",
    "        Takes an instance of `XGBRegressor` model and tracks the hyperparameter tuning\n",
    "        experiment on training set using `mlflow` and `optuna`.  \n",
    "        Registers the best version of the model according to a specified metric (to be implemented).\n",
    "        \n",
    "        -------     \n",
    "        params:\n",
    "        -------\n",
    "        `experiment_name`: `str`\n",
    "            the name of the experiment used to store runs in mlflow, \n",
    "            as well as the name of the optuna study\n",
    "        `model_name`: `str`\n",
    "            the name the final model will have in the registry\n",
    "        `train_df`: `pd.DataFrame`\n",
    "            the training data for the model.\n",
    "        `target_col`: `str`\n",
    "            the time-series target column\n",
    "        `exclude_cols`: `list`  \n",
    "            columns in dataset that should not be used\n",
    "        `artifact_path`: `str`\n",
    "            the path pointing to the mlflow artifact\n",
    "        `metrics`: `list`\n",
    "            list of the metrics to track in the mlflow experiment run.\n",
    "        `params`: `Optional[Dict]`\n",
    "            optional dictionary of parameters to use\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "\n",
    "        if len(categorical_features) > 0: \n",
    "           train_df = pd.get_dummies(train_df, columns=cat_columns)\n",
    "\n",
    "        X = train_df.drop([target_col] + exclude_cols, axis=1)\n",
    "        y = train_df[target_col]\n",
    "        # unique year-month combinations -> to be used in cross-validation\n",
    "        timesteps = np.sort(np.array(\n",
    "            pd.to_datetime(X[['year', 'month']].assign(day=1)).unique().tolist()\n",
    "        ))\n",
    "        \n",
    "        # define mlflow callback Handler for optuna \n",
    "        mlflc = MLflowCallback(\n",
    "            metric_name=[\"MAE\"]\n",
    "        )\n",
    "    \n",
    "        @mlflc.track_in_mlflow() # decorator to allow mlflow logging\n",
    "        def objective(trial):\n",
    "            params = {\n",
    "                'eval_metric': 'mae',\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 50, 200, log=True),\n",
    "                'eta': trial.suggest_float('eta', 0.01, 0.95,log=True),\n",
    "                'max_depth': trial.suggest_int('max_depth', 1, 10, log=True),\n",
    "                'min_child_weight': trial.suggest_int('min_child_weight', 1, 25, log=True),\n",
    "                'colsample_bytree': trial.suggest_float(\"colsample_bytree\", 0.1, 1, log=True),\n",
    "                'colsample_bylevel': trial.suggest_float(\"colsample_bylevel\", 0.1, 1, log=True),\n",
    "                'colsample_bynode': trial.suggest_float(\"colsample_bynode\", 0.1, 1, log=True),\n",
    "                'subsample': trial.suggest_float(\"subsample\", 0.5, 1, log=True),\n",
    "                'lambda': trial.suggest_float('lambda', 1e-3, 10.0, log=True),\n",
    "                'alpha': trial.suggest_float('alpha', 1e-3, 10.0, log=True)\n",
    "            }\n",
    "            cv = TimeSeriesSplit(n_splits=3) # cross validation\n",
    "            cv_mae = [None]*3\n",
    "            cv_mape = [None]*3\n",
    "            cv_rmse = [None]*3\n",
    "            for i, (train_index, test_index) in enumerate(cv.split(timesteps)):\n",
    "                cv_mae[i], cv_mape[i], cv_rmse[i] = self.fit_and_test_fold(\n",
    "                    params,\n",
    "                    X, \n",
    "                    y, \n",
    "                    timesteps[train_index], \n",
    "                    timesteps[test_index]\n",
    "                )\n",
    "            trial.set_user_attr('split_mae', cv_mae)\n",
    "            trial.set_user_attr('split_mape', cv_mape)\n",
    "            trial.set_user_attr('split_rmse', cv_rmse)\n",
    "\n",
    "            mlflow.log_metrics(\n",
    "                {\n",
    "                    \"MAE\":np.mean(cv_mae),\n",
    "                    \"MAPE\":np.mean(cv_mape),\n",
    "                    \"RMSE\":np.mean(cv_rmse) \n",
    "                }\n",
    "            )\n",
    "            return np.mean(cv_mae) \n",
    "\n",
    "        \n",
    "        sampler = optuna.samplers.TPESampler(\n",
    "            n_startup_trials=10, \n",
    "            seed=0\n",
    "        )\n",
    "\n",
    "        self.study = optuna.create_study(\n",
    "            directions=['minimize'],\n",
    "            sampler=sampler,\n",
    "            study_name=experiment_name\n",
    "        )\n",
    "\n",
    "        self.study.optimize(objective, n_trials=2, timeout= 7200, callbacks=[mlflc]) \n",
    "        \n",
    "        # # search for the best run at the end of the experiment # not implemented now bc of callback bug\n",
    "        # best_run = mlflow.search_runs(max_results=1,order_by=[\"metrics.MAE\"]).run_id\n",
    "        # # register new model version in mlflow\n",
    "        # self.result = mlflow.register_model(\n",
    "        #     model_uri=f\"runs:/{best_run}/{artifact_path}\",\n",
    "        #     name=self.model_name\n",
    "        # )\n",
    "\n",
    "    def forecast(\n",
    "        self, \n",
    "        input_data: pd.DataFrame,\n",
    "        use_best_from_run: bool=True,\n",
    "        use_env_model: Literal[\"Staging\", \"Production\", None]=None,\n",
    "        use_version: int=None\n",
    "        ) -> pd.DataFrame:\n",
    "        \"\"\" \n",
    "        Fetches a version of the model from the mlflow backend and uses it\n",
    "        to perform prediction on new input data.  \n",
    "        What version is used depends on params settings, \n",
    "        defaults to using the best version from the last experiment run (currently not implemented). \n",
    "        -------     \n",
    "        params:\n",
    "        -------\n",
    "        `input_data`: `pd.DataFrame`\n",
    "            the input data for prediction,\n",
    "              must have the same schema as what's in the model's signature.\n",
    "        `use_best_from_run`: `bool=True`      \n",
    "            use the best model from the current series of iterations, defaults to True\n",
    "        `use_env_model`: `Literal[\"Staging\", \"Production\", None]=None`\n",
    "            use model from a given mlflow environment, defaults to None.  \n",
    "            Said model might come from past iterations, depending on what you decide in the UI\n",
    "        `use_version`: `int=None`\n",
    "            use a previously trained version of the model. \n",
    "            Said version must have been registered from a previous iteration,  \n",
    "            either by the UI or with mlflow's API\n",
    "        \"\"\"\n",
    "        if use_best_from_run:\n",
    "            # not implemented now bc of callback bug\n",
    "            use_prod_model=None\n",
    "            use_version=None\n",
    "        \n",
    "            # model = mlflow.pyfunc.load_model(\n",
    "            #     model_uri=f\"models:/{self.model_name}/{self.result.version}\"\n",
    "            # )\n",
    "            # y_pred = model.predict(input_data)\n",
    "            # return y_pred\n",
    "        \n",
    "        if use_env_model is not None:\n",
    "            use_version = None\n",
    "\n",
    "            model = mlflow.pyfunc.load_model(\n",
    "                # get registered model in given environment\n",
    "                model_uri=f\"models:/{self.model_name}/{use_env_model}\"\n",
    "            )\n",
    "            y_pred = model.predict(input_data)\n",
    "            return y_pred\n",
    "\n",
    "        if use_version is not None:\n",
    "            # get specific registered version of model\n",
    "            model = mlflow.pyfunc.load_model(\n",
    "                model_uri=f\"models:/{self.model_name}/{use_version}\"\n",
    "            )\n",
    "            y_pred = model.predict(input_data)\n",
    "            return y_pred\n",
    "\n",
    "        \n",
    "        if (not use_best_from_run) & (use_env_model is None) & (use_version is None):\n",
    "            return ValueError(\n",
    "                    \"You must specify which kind of XGBoostForecaster you intend to use for prediction\"\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-19 16:27:13,327] A new study created in memory with name: xgboost\n",
      "[I 2023-11-19 16:27:41,162] Trial 0 finished with value: 192.43502468877696 and parameters: {'n_estimators': 107, 'eta': 0.25968501651282105, 'max_depth': 3, 'min_child_weight': 4, 'colsample_bytree': 0.2652496376759476, 'colsample_bylevel': 0.4424804764191636, 'colsample_bynode': 0.2738969595234697, 'subsample': 0.927727492754704, 'lambda': 7.155682161754866, 'alpha': 0.03417952912061012}. Best is trial 0 with value: 192.43502468877696.\n",
      "[I 2023-11-19 16:28:14,500] Trial 1 finished with value: 186.59206557742948 and parameters: {'n_estimators': 150, 'eta': 0.1111752123160987, 'max_depth': 3, 'min_child_weight': 19, 'colsample_bytree': 0.11777037507521713, 'colsample_bylevel': 0.12221634728708944, 'colsample_bynode': 0.10476552591086516, 'subsample': 0.8904582312865974, 'lambda': 1.2960656597279734, 'alpha': 3.020289640158666}. Best is trial 1 with value: 186.59206557742948.\n"
     ]
    }
   ],
   "source": [
    "xgbf = XGBoostForecaster()\n",
    "\n",
    "xgbf.train_model(\n",
    "    train_df=df_train,\n",
    "    target_col=\"target\",\n",
    "    model_name=\"xgboost_enefit\",\n",
    "    exclude_cols=not_feature_columns,\n",
    "    categorical_features=cat_columns\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enefit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
